{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3993bf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d169c062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81e88997",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TAVILY_API_KEY'] = os.getenv('TAVILY_API_KEY')\n",
    "os.environ['GROQ_API_KEY'] = os.getenv('GROQ_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c040e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "tavily = TavilySearchResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1df4766f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = tavily.invoke(\"what is large language model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "784e038a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Large language model - Wikipedia',\n",
       "  'url': 'https://en.wikipedia.org/wiki/Large_language_model',\n",
       "  'content': 'Related articlesGlossary of artificial intelligenceList of datasets for machine-learning researchList of datasets in computer vision and image processingOutline of machine learning\\nvte\\nA large language model (LLM) is a type of machine learning model designed for natural language processing tasks such as language generation. LLMs are language models with many parameters, and are trained with self-supervised learning on a vast amount of text. [...] tasks and understanding. The NTL Model outlines how specific neural structures of the human brain shape the nature of thought and language and in turn what are the computational properties of such neural systems that can be applied to model thought and language in a computer system. After a framework for modeling language in a computer systems was established, the focus shifted to establishing frameworks for computer systems to generate language with acceptable grammar. In his 2014 book titled [...] Let \\n\\n\\n\\nx\\n\\n\\n{\\\\displaystyle x}\\n\\n be the number of parameter count, and \\n\\n\\n\\ny\\n\\n\\n{\\\\displaystyle y}\\n\\n be the performance of the model.\\n\\nInterpretation\\n\\nLarge language models by themselves are black boxes, and it is not clear how they can perform linguistic tasks. Similarly, it is unclear if or how LLMs should be viewed as models of the human brain and/or human mind.[104]',\n",
       "  'score': 0.94989765},\n",
       " {'title': 'What are Large Language Models (LLMs)? - TechTarget',\n",
       "  'url': 'https://www.techtarget.com/whatis/definition/large-language-model-LLM',\n",
       "  'content': \"A large language model is a type of artificial intelligence algorithm that uses\\xa0deep learning\\xa0techniques and massively large data sets to understand, summarize, generate and predict new content. The term\\xa0generative AI\\xa0also is closely connected with LLMs, which are, in fact, a type of generative AI that has been specifically architected to help generate text-based content. [...] An LLM is the evolution of the language model concept in AI that dramatically expands the data used for training and inference. In turn, it provides a massive increase in the capabilities of the AI model. While there isn't a universally accepted figure for how large the data set for training needs to be, an LLM typically has at least one billion or more parameters. Parameters\\xa0are a\\xa0machine learning\\xa0term for the variables present in the model on which it was trained that can be used to infer new [...] On the other hand, the use of large language models could drive new instances of\\xa0shadow IT\\xa0in organizations. CIOs will need to implement usage guardrails and provide training to avoid data privacy problems and other issues. LLMs could also create new cybersecurity challenges by enabling attackers to write more persuasive and realistic phishing emails or other malicious communications.\",\n",
       "  'score': 0.94225764},\n",
       " {'title': 'What is LLM? - Large Language Models Explained - AWS',\n",
       "  'url': 'https://aws.amazon.com/what-is/large-language-model/',\n",
       "  'content': 'What is LLM (Large Language Model)?\\n\\nWhat are Large Language Models?\\n\\nLarge language models, also known as LLMs, are very large deep learning models that are pre-trained on vast amounts of data. The underlying transformer is a set of neural networks that consist of an encoder and a decoder with self-attention capabilities. The encoder and decoder extract meanings from a sequence of text and understand the relationships between words and phrases in it. [...] Large language models are incredibly flexible. One model can perform completely different tasks such as answering questions, summarizing documents, translating languages and completing sentences. LLMs have the potential to disrupt content creation and the way people use search engines and virtual assistants. [...] While not perfect, LLMs are demonstrating a remarkable ability to make predictions based on a relatively small number of prompts or inputs. LLMs can be used for generative AI (artificial intelligence) to produce content based on input prompts in human language.\\n\\nLLMs are big, very big. They can consider billions of parameters and have many possible uses. Here are some examples:\\n\\nRead more about\\xa0generative AI\\xa0»\\n\\nRead more about\\xa0foundation models\\xa0»\\n\\nHow do large language models work?',\n",
       "  'score': 0.9418739},\n",
       " {'title': 'What is an LLM (large language model)? - Cloudflare',\n",
       "  'url': 'https://www.cloudflare.com/learning/ai/what-is-large-language-model/',\n",
       "  'content': 'A large language model (LLM) is a type of artificial intelligence (AI) program that can recognize and generate text, among other tasks. LLMs are trained on huge sets of data — hence the name \"large.\" LLMs are built on machine learning: specifically, a type of neural network called a transformer model. [...] Log in\\nSolutionsProductsPricingResourcesPartnersWhy Cloudflare\\nSupport\\nSign up\\nWhat is a large language model (LLM)?\\nLarge language models (LLMs) are machine learning models that can comprehend and generate human language text. They work by analyzing massive data sets of language.\\nLearning Center\\n\\n\\nWhat is artificial intelligence (AI)?\\n\\n\\nWhat is a large language model (LLM)?\\n\\n\\nMachine learning\\n\\nGlossary\\n\\nLearning Objectives\\nAfter reading this article you will be able to: [...] In simpler terms, an LLM is a computer program that has been fed enough examples to be able to recognize and interpret human language or other types of complex data. Many LLMs are trained on data that has been gathered from the Internet — thousands or millions of gigabytes\\' worth of text. But the quality of the samples impacts how well LLMs will learn natural language, so an LLM\\'s programmers may use a more curated data set.',\n",
       "  'score': 0.9416167},\n",
       " {'title': 'What is a large language model (LLM)?',\n",
       "  'url': 'https://ask.library.arizona.edu/faq/407985',\n",
       "  'content': 'A large language model (LLM) is a type of artificial intelligence that can generate human language and perform related tasks. These models are trained on',\n",
       "  'score': 0.9405774}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ecc871b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Related articlesGlossary of artificial intelligenceList of datasets for machine-learning researchList of datasets in computer vision and image processingOutline of machine learning\\nvte\\nA large language model (LLM) is a type of machine learning model designed for natural language processing tasks such as language generation. LLMs are language models with many parameters, and are trained with self-supervised learning on a vast amount of text. [...] tasks and understanding. The NTL Model outlines how specific neural structures of the human brain shape the nature of thought and language and in turn what are the computational properties of such neural systems that can be applied to model thought and language in a computer system. After a framework for modeling language in a computer systems was established, the focus shifted to establishing frameworks for computer systems to generate language with acceptable grammar. In his 2014 book titled [...] Let \\n\\n\\n\\nx\\n\\n\\n{\\\\displaystyle x}\\n\\n be the number of parameter count, and \\n\\n\\n\\ny\\n\\n\\n{\\\\displaystyle y}\\n\\n be the performance of the model.\\n\\nInterpretation\\n\\nLarge language models by themselves are black boxes, and it is not clear how they can perform linguistic tasks. Similarly, it is unclear if or how LLMs should be viewed as models of the human brain and/or human mind.[104]'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0]['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7067bc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import ArxivQueryRun\n",
    "from langchain_community.tools import WikipediaQueryRun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88d6a98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import ArxivAPIWrapper\n",
    "from langchain_community.utilities import WikipediaAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6046dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_api = WikipediaAPIWrapper(top_k_results=3, doc_content_chars_max=200)\n",
    "wikipedia = WikipediaQueryRun(api_wrapper=wiki_api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12f9030a",
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_api = ArxivAPIWrapper(top_k_results=3, doc_content_chars_max=200)\n",
    "arxiv = ArxivQueryRun(api_wrapper=arxiv_api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99b09d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [wikipedia, arxiv, tavily]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8de3983",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(model='qwen-qwq-32b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2133b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm.bind_tools(tools=tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aafceeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = llm_with_tools.invoke(\"what is large language model?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "95fc18bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'wikipedia',\n",
       "  'args': {'query': 'large language model'},\n",
       "  'id': 'call_kxcc',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_calls = result.tool_calls\n",
    "tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d4a50630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Page: Large language model\\nSummary: A large language model (LLM) is a type of machine learning model designed for natural language processing tasks such as language generation. LLMs are language model'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikipedia.invoke(tool_calls[0]['args'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5ee7cfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import AnyMessage, HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "288c4276",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages : Annotated[list, add_messages]\n",
    "\n",
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2d9bacab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLMNode:\n",
    "    def __init__(self, llm):\n",
    "        self.llm = llm\n",
    "    def __call__(self, state:State):\n",
    "        return {\"messages\": [self.llm.invoke(state['messages'])]}\n",
    "    \n",
    "llm_node = LLMNode(llm_with_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "153e4627",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "tool_node = ToolNode(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3e49514b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x26ab237fcb0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder.add_node(\"llm\", llm_node)\n",
    "graph_builder.add_node(\"tools\", tool_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "745fece2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x26ab237fcb0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import START\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "graph_builder.add_edge(START, \"llm\")\n",
    "graph_builder.add_conditional_edges(\"llm\", tools_condition)\n",
    "graph_builder.add_edge(\"tools\", \"llm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f516bf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "765af802",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to render the graph using the Mermaid.INK API. Status code: 502.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[59]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mIPython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image, display\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m display(Image(\u001b[43magent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdraw_mermaid_png\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nikhil\\.conda\\envs\\langgraph\\Lib\\site-packages\\langchain_core\\runnables\\graph.py:677\u001b[39m, in \u001b[36mGraph.draw_mermaid_png\u001b[39m\u001b[34m(self, curve_style, node_colors, wrap_label_n_words, output_file_path, draw_method, background_color, padding, frontmatter_config)\u001b[39m\n\u001b[32m    669\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrunnables\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgraph_mermaid\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m draw_mermaid_png\n\u001b[32m    671\u001b[39m mermaid_syntax = \u001b[38;5;28mself\u001b[39m.draw_mermaid(\n\u001b[32m    672\u001b[39m     curve_style=curve_style,\n\u001b[32m    673\u001b[39m     node_colors=node_colors,\n\u001b[32m    674\u001b[39m     wrap_label_n_words=wrap_label_n_words,\n\u001b[32m    675\u001b[39m     frontmatter_config=frontmatter_config,\n\u001b[32m    676\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m677\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw_mermaid_png\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmermaid_syntax\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmermaid_syntax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    680\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdraw_method\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdraw_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    682\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    683\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nikhil\\.conda\\envs\\langgraph\\Lib\\site-packages\\langchain_core\\runnables\\graph_mermaid.py:285\u001b[39m, in \u001b[36mdraw_mermaid_png\u001b[39m\u001b[34m(mermaid_syntax, output_file_path, draw_method, background_color, padding)\u001b[39m\n\u001b[32m    279\u001b[39m     img_bytes = asyncio.run(\n\u001b[32m    280\u001b[39m         _render_mermaid_using_pyppeteer(\n\u001b[32m    281\u001b[39m             mermaid_syntax, output_file_path, background_color, padding\n\u001b[32m    282\u001b[39m         )\n\u001b[32m    283\u001b[39m     )\n\u001b[32m    284\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m draw_method == MermaidDrawMethod.API:\n\u001b[32m--> \u001b[39m\u001b[32m285\u001b[39m     img_bytes = \u001b[43m_render_mermaid_using_api\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    286\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmermaid_syntax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackground_color\u001b[49m\n\u001b[32m    287\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    288\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    289\u001b[39m     supported_methods = \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join([m.value \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m MermaidDrawMethod])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nikhil\\.conda\\envs\\langgraph\\Lib\\site-packages\\langchain_core\\runnables\\graph_mermaid.py:414\u001b[39m, in \u001b[36m_render_mermaid_using_api\u001b[39m\u001b[34m(mermaid_syntax, output_file_path, background_color, file_type)\u001b[39m\n\u001b[32m    409\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m img_bytes\n\u001b[32m    410\u001b[39m msg = (\n\u001b[32m    411\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to render the graph using the Mermaid.INK API. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    412\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mStatus code: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    413\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m414\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[31mValueError\u001b[39m: Failed to render the graph using the Mermaid.INK API. Status code: 502."
     ]
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(agent.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "702aea66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "what is MCP in AI\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  wikipedia (call_e6h2)\n",
      " Call ID: call_e6h2\n",
      "  Args:\n",
      "    query: MCP AI\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: wikipedia\n",
      "\n",
      "Page: Model Context Protocol\n",
      "Summary: The Model Context Protocol (MCP) is an open standard developed by the artificial intelligence company Anthropic for enabling large language model (LLM) applicatio\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The Model Context Protocol (MCP) is an open standard developed by Anthropic (an artificial intelligence company) to enable interoperability and advanced capabilities in large language models (LLMs) and their applications. \n",
      "\n",
      "Key aspects of MCP include:\n",
      "1. **Purpose**: It allows LLMs to better understand and generate structured data (e.g., forms, code, or tables) while maintaining context and safety.\n",
      "2. **Features**: It provides a structured way to format inputs and outputs, enabling features like:\n",
      "   - **Step-by-step reasoning**  \n",
      "   - **Structured data handling**  \n",
      "   - **Reduced prompt injection risks**  \n",
      "3. **Adoption**: It is used in Anthropic’s Claude models and is designed for broader industry adoption as an open protocol.\n",
      "\n",
      "MCP addresses challenges in how AI systems process complex, real-world tasks by standardizing communication between models and applications.\n"
     ]
    }
   ],
   "source": [
    "messages = agent.invoke({\"messages\":HumanMessage(content=\"what is MCP in AI\")})\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4bc3841f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The Model Context Protocol (MCP) is an open standard developed by Anthropic (an artificial intelligence company) to enable interoperability and advanced capabilities in large language models (LLMs) and their applications. \n",
      "\n",
      "Key aspects of MCP include:\n",
      "1. **Purpose**: It allows LLMs to better understand and generate structured data (e.g., forms, code, or tables) while maintaining context and safety.\n",
      "2. **Features**: It provides a structured way to format inputs and outputs, enabling features like:\n",
      "   - **Step-by-step reasoning**  \n",
      "   - **Structured data handling**  \n",
      "   - **Reduced prompt injection risks**  \n",
      "3. **Adoption**: It is used in Anthropic’s Claude models and is designed for broader industry adoption as an open protocol.\n",
      "\n",
      "MCP addresses challenges in how AI systems process complex, real-world tasks by standardizing communication between models and applications.\n"
     ]
    }
   ],
   "source": [
    "messages['messages'][3].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22143a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0e32b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
